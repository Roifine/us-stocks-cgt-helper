import pandas as pd
import numpy as np
from datetime import datetime
import os
import glob

def get_exchange_rate(date_str, base_currency='USD', target_currency='AUD'):
    """
    Get historical exchange rate for a specific date.
    For production use, you'll need a proper API key from a service like exchangerate-api.com
    This is a placeholder function - you'll need to implement with your preferred API.
    """
    # Placeholder function - replace with actual API call
    # For now, using approximate historical rates
    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
    
    # Approximate USD/AUD rates for different periods
    if date_obj >= datetime(2023, 7, 1) and date_obj <= datetime(2024, 6, 30):
        return 1.45  # Approximate average for FY 2023-24
    elif date_obj >= datetime(2024, 7, 1) and date_obj <= datetime(2024, 12, 31):
        return 1.48  # Approximate average for Jul-Dec 2024
    elif date_obj >= datetime(2025, 1, 1) and date_obj <= datetime(2025, 6, 30):
        return 1.52  # Approximate average for Jan-Jun 2025
    else:
        return 1.50  # Default fallback

def load_and_combine_csv_files(csv_files):
    """
    Load multiple CSV files and combine them into a single DataFrame.
    
    Args:
        csv_files (list): List of CSV file paths
    
    Returns:
        pandas.DataFrame: Combined DataFrame
    """
    
    all_dataframes = []
    
    print("Loading CSV files...")
    for csv_file in csv_files:
        if os.path.exists(csv_file):
            try:
                df = pd.read_csv(csv_file)
                df['Source_File'] = os.path.basename(csv_file)  # Track which file each record came from
                all_dataframes.append(df)
                print(f"‚úÖ Loaded {len(df)} transactions from {csv_file}")
                
                # Show date range for this file
                if 'Trade Date' in df.columns:
                    df['Trade Date'] = pd.to_datetime(df['Trade Date'])
                    min_date = df['Trade Date'].min().strftime('%Y-%m-%d')
                    max_date = df['Trade Date'].max().strftime('%Y-%m-%d')
                    print(f"   üìÖ Date range: {min_date} to {max_date}")
                    
            except Exception as e:
                print(f"‚ùå Error loading {csv_file}: {e}")
        else:
            print(f"‚ùå File not found: {csv_file}")
    
    if not all_dataframes:
        raise ValueError("No CSV files loaded successfully")
    
    # Combine all dataframes
    combined_df = pd.concat(all_dataframes, ignore_index=True)
    
    print(f"\nüìä Combined Summary:")
    print(f"Total transactions: {len(combined_df)}")
    print(f"Source files: {len(csv_files)}")
    
    # Show transactions by source file
    source_counts = combined_df['Source_File'].value_counts()
    for source, count in source_counts.items():
        print(f"  {source}: {count} transactions")
    
    return combined_df

def process_multiple_csv_trading_data(csv_files, financial_year=None, output_suffix=""):
    """
    Process trading data from multiple CSV files to separate buy and sell transactions.
    
    Args:
        csv_files (list): List of CSV file paths
        financial_year (str): Optional filter for specific FY (e.g., "2024-25"), None for all data
        output_suffix (str): Optional suffix for output filename
    
    Returns:
        tuple: (sales_df, buys_df)
    """
    
    print("="*70)
    print("MULTI-CSV TRADING DATA PROCESSOR")
    print("="*70)
    
    # Load and combine all CSV files
    df = load_and_combine_csv_files(csv_files)
    
    # Convert Trade Date to datetime
    df['Trade Date'] = pd.to_datetime(df['Trade Date'])
    
    # Optional: Filter by financial year
    if financial_year:
        print(f"\nüóìÔ∏è Filtering for Australian Financial Year {financial_year}")
        if financial_year == "2023-24":
            fy_start = datetime(2023, 7, 1)
            fy_end = datetime(2024, 6, 30)
        elif financial_year == "2024-25":
            fy_start = datetime(2024, 7, 1)
            fy_end = datetime(2025, 6, 30)
        else:
            # Parse custom format like "2024-25"
            start_year = int(financial_year.split('-')[0])
            fy_start = datetime(start_year, 7, 1)
            fy_end = datetime(start_year + 1, 6, 30)
        
        df_filtered = df[(df['Trade Date'] >= fy_start) & (df['Trade Date'] <= fy_end)].copy()
        print(f"Before FY filter: {len(df)} transactions")
        print(f"After FY {financial_year} filter: {len(df_filtered)} transactions")
        df = df_filtered
    else:
        print(f"\nüìÖ Processing all transactions across all years")
        print(f"Date range: {df['Trade Date'].min().strftime('%Y-%m-%d')} to {df['Trade Date'].max().strftime('%Y-%m-%d')}")
    
    # Remove currency transactions (symbols starting with AUD.USD or similar currency patterns)
    print(f"\nüîÑ Cleaning data...")
    print(f"Before removing currency transactions: {len(df)} records")
    
    # More comprehensive currency filtering
    currency_patterns = ['AUD.USD', 'USD.', 'EUR.', 'GBP.', 'JPY.', 'CAD.']
    currency_mask = df['Symbol'].str.contains('|'.join(currency_patterns), na=False)
    df_clean = df[~currency_mask].copy()
    
    removed_currency = len(df) - len(df_clean)
    if removed_currency > 0:
        print(f"Removed {removed_currency} currency transactions")
    print(f"After removing currency transactions: {len(df_clean)} records")
    
    # Handle summary + breakdown duplication
    print("\nüîç Checking for duplicate breakdown transactions...")
    
    # Group by Symbol, Trade Date, Type, Price to find potential duplications
    grouped = df_clean.groupby(['Symbol', 'Trade Date', 'Type', 'Price (USD)'])
    
    records_to_keep = []
    duplicates_removed = 0
    
    for (symbol, date, trade_type, price), group in grouped:
        if len(group) == 1:
            # Single transaction, keep it
            records_to_keep.append(group.iloc[0])
        else:
            # Multiple transactions for same symbol/date/type/price
            quantities = group['Quantity'].tolist()
            
            # Check if one quantity equals the sum of the others (summary + breakdown pattern)
            summary_found = False
            for i, qty in enumerate(quantities):
                other_quantities = quantities[:i] + quantities[i+1:]
                if abs(qty - sum(other_quantities)) < 0.01:  # Small tolerance for floating point
                    # This quantity is the summary, keep only this record
                    records_to_keep.append(group.iloc[i])
                    summary_found = True
                    duplicates_removed += len(group) - 1
                    print(f"  ‚úÇÔ∏è  Found summary transaction for {symbol} on {date.strftime('%Y-%m-%d')}: kept {qty}, removed {len(group)-1} breakdown items")
                    break
            
            if not summary_found:
                # No clear summary pattern, sum all quantities (original behavior)
                consolidated_record = group.iloc[0].copy()
                consolidated_record['Quantity'] = sum(quantities)
                consolidated_record['Proceeds (USD)'] = group['Proceeds (USD)'].sum()
                consolidated_record['Commission (USD)'] = group['Commission (USD)'].sum()
                records_to_keep.append(consolidated_record)
                duplicates_removed += len(group) - 1
                print(f"  üîÑ No summary pattern found for {symbol} on {date.strftime('%Y-%m-%d')}, consolidated {len(quantities)} records")
    
    df_consolidated = pd.DataFrame(records_to_keep)
    print(f"After removing breakdown duplicates: {len(df_consolidated)} records (removed {duplicates_removed} duplicates)")
    
    # Remove any rows where quantity becomes zero after consolidation
    df_consolidated = df_consolidated[abs(df_consolidated['Quantity']) > 0.01].copy()
    print(f"After removing zero quantity records: {len(df_consolidated)} records")
    
    # Separate buys and sells
    sales_df = df_consolidated[df_consolidated['Type'] == 'SELL'].copy()
    buys_df = df_consolidated[df_consolidated['Type'] == 'BUY'].copy()
    
    print(f"\nüìà Transaction Summary:")
    print(f"Sale transactions: {len(sales_df)}")
    print(f"Buy transactions: {len(buys_df)}")
    print(f"Unique symbols traded: {len(df_consolidated['Symbol'].unique())}")
    
    # Show symbol breakdown
    symbol_counts = df_consolidated['Symbol'].value_counts()
    print(f"\nTop 10 most traded symbols:")
    for symbol, count in symbol_counts.head(10).items():
        buy_count = len(buys_df[buys_df['Symbol'] == symbol])
        sell_count = len(sales_df[sales_df['Symbol'] == symbol])
        print(f"  {symbol}: {count} total ({buy_count} buys, {sell_count} sells)")
    
    # Add exchange rates and AUD calculations for both sheets
    print(f"\nüí± Adding exchange rates and AUD calculations...")
    
    if len(sales_df) > 0:
        sales_df['Exchange Rate (USD/AUD)'] = sales_df['Trade Date'].apply(
            lambda x: get_exchange_rate(x.strftime('%Y-%m-%d'))
        )
        sales_df['Proceeds (AUD)'] = (
            (sales_df['Proceeds (USD)'] + sales_df['Commission (USD)']) * 
            sales_df['Exchange Rate (USD/AUD)']
        )
    
    if len(buys_df) > 0:
        buys_df['Exchange Rate (USD/AUD)'] = buys_df['Trade Date'].apply(
            lambda x: get_exchange_rate(x.strftime('%Y-%m-%d'))
        )
        buys_df['Cost (AUD)'] = (
            (abs(buys_df['Proceeds (USD)']) + abs(buys_df['Commission (USD)'])) * 
            buys_df['Exchange Rate (USD/AUD)']
        )
    
    # Generate output filename
    if financial_year:
        fy_suffix = f"_FY{financial_year}"
    else:
        min_year = df_consolidated['Trade Date'].min().year
        max_year = df_consolidated['Trade Date'].max().year
        if min_year == max_year:
            fy_suffix = f"_{min_year}"
        else:
            fy_suffix = f"_{min_year}-{max_year}"
    
    output_file = f"consolidated_transactions{fy_suffix}{output_suffix}.xlsx"
    
    # Write to Excel with multiple sheets
    print(f"\nüíæ Saving results to: {output_file}")
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # Sheet 1: All sale transactions
        if len(sales_df) > 0:
            sales_df.to_excel(writer, sheet_name='Sale_Transactions', index=False)
        
        # Sheet 2: All buy transactions  
        if len(buys_df) > 0:
            buys_df.to_excel(writer, sheet_name='Buy_Transactions', index=False)
        
        # Sheet 3: Summary by symbol
        symbol_summary = df_consolidated.groupby('Symbol').agg({
            'Quantity': 'sum',
            'Proceeds (USD)': 'sum',
            'Commission (USD)': 'sum'
        }).round(2)
        symbol_summary.to_excel(writer, sheet_name='Summary_by_Symbol')
        
        # Sheet 4: Summary by source file
        source_summary = df_consolidated.groupby('Source_File').agg({
            'Quantity': 'count',
            'Proceeds (USD)': 'sum',
            'Commission (USD)': 'sum'
        }).round(2)
        source_summary.columns = ['Transaction_Count', 'Total_Proceeds_USD', 'Total_Commission_USD']
        source_summary.to_excel(writer, sheet_name='Summary_by_Source')
    
    print(f"\n‚úÖ Analysis complete!")
    print(f"üìÑ Results saved to: {output_file}")
    
    return sales_df, buys_df

def find_csv_files_by_pattern(pattern):
    """
    Find CSV files matching a pattern (e.g., "*trades*.csv")
    
    Args:
        pattern (str): File pattern to match
    
    Returns:
        list: List of matching CSV file paths
    """
    files = glob.glob(pattern)
    csv_files = [f for f in files if f.endswith('.csv')]
    return sorted(csv_files)

def main():
    """
    Main function with multiple usage examples
    """
    
    print("üöÄ Multi-CSV Trading Data Processor")
    print("="*50)
    
    # METHOD 1: Specify exact files
    csv_files_method1 = [
        "cleaned_trades_2024-25.csv",  # Your existing 2024-25 data
        "50074435_20230907_20240628_parsed.csv",  # Your parsed HTML data (2023-24)
        # Add more files as needed
    ]
    
    # METHOD 2: Auto-find files by pattern
    csv_files_method2 = find_csv_files_by_pattern("*trades*.csv") + find_csv_files_by_pattern("*parsed*.csv")
    
    # METHOD 3: Manual file list (update as needed)
    csv_files_method3 = [
        # Add your actual file names here
    ]
    
    # Choose which method to use
    print("Choose processing method:")
    print("1. Specific files (recommended)")
    print("2. Auto-find files by pattern") 
    print("3. All transactions (no FY filter)")
    
    # For now, let's use method 1 with the files that exist
    existing_files = []
    for file in csv_files_method1:
        if os.path.exists(file):
            existing_files.append(file)
        else:
            print(f"‚ö†Ô∏è  File not found: {file}")
    
    if not existing_files:
        print("‚ùå No CSV files found. Please check your file paths.")
        return
    
    print(f"\nüìÅ Processing files: {existing_files}")
    
    try:
        # Process all years combined
        print("\n" + "="*50)
        print("PROCESSING ALL YEARS COMBINED")
        print("="*50)
        sales_all, buys_all = process_multiple_csv_trading_data(
            existing_files, 
            financial_year=None,  # No filter - all years
            output_suffix="_all_years"
        )
        
        # Process specific financial year if you want
        print("\n" + "="*50)
        print("PROCESSING FY 2024-25 ONLY")  
        print("="*50)
        sales_fy25, buys_fy25 = process_multiple_csv_trading_data(
            existing_files,
            financial_year="2024-25",
            output_suffix="_FY2024-25_only"
        )
        
        print("\nüéâ Processing completed successfully!")
        print(f"\nFiles created:")
        print(f"üìÑ consolidated_transactions_all_years.xlsx - All data combined")
        print(f"üìÑ consolidated_transactions_FY2024-25_FY2024-25_only.xlsx - FY 2024-25 only")
        
        print(f"\nüìä Quick Summary (All Years):")
        print(f"Total buy transactions: {len(buys_all)}")
        print(f"Total sell transactions: {len(sales_all)}")
        print(f"Unique symbols: {len(set(list(buys_all['Symbol'].unique()) + list(sales_all['Symbol'].unique())))}")
        
    except Exception as e:
        print(f"‚ùå Error processing files: {e}")
        print("Please ensure your CSV files exist and have the correct format.")

if __name__ == "__main__":
    main()

# Usage Examples:
"""
# Example 1: Process specific files
csv_files = ["file1.csv", "file2.csv", "file3.csv"] 
sales_df, buys_df = process_multiple_csv_trading_data(csv_files)

# Example 2: Process all files for specific financial year
csv_files = ["trades_2023.csv", "trades_2024.csv", "trades_2025.csv"]
sales_df, buys_df = process_multiple_csv_trading_data(csv_files, financial_year="2024-25")

# Example 3: Auto-find and process files
csv_files = find_csv_files_by_pattern("*trades*.csv")
sales_df, buys_df = process_multiple_csv_trading_data(csv_files)
"""